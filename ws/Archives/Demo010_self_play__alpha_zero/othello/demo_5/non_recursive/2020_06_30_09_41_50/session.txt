2020-06-30 09:40:34,543 - @@@ DEMO NAME:: train_mini
2020-06-30 09:40:34,544 - @@@ PATH:: /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/train_mini.py
2020-06-30 09:40:34,547 - 
2020-06-30 09:40:34,548 - SESSION ID: session_1
2020-06-30 09:40:34,548 - model_acceptance_win_ratio=0.6
2020-06-30 09:40:34,549 - win_ratio_reduction_rate=1
2020-06-30 09:40:34,549 - num_training_eval_games=4
2020-06-30 09:40:34,550 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-30 09:40:34,550 - num_episodes=3
2020-06-30 09:40:34,550 - num_iterations=2
2020-06-30 09:40:34,550 - epochs=2
2020-06-30 09:40:34,551 - num_of_mcts_simulations=12
2020-06-30 09:40:35,139 - @@@ Model loaded
2020-06-30 09:40:35,139 - 
2020-06-30 09:40:35,139 - SAMPLE GEN ITERATION 1 of 2
2020-06-30 09:40:35,171 - @@@ Upgraded Model
2020-06-30 09:40:39,578 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-30 09:40:44,089 -   SAMPLE GEN EPISODE 2 of 3:  160 samples generated
2020-06-30 09:40:47,930 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-30 09:40:47,930 - Total Samples Collected: 472
2020-06-30 09:40:47,930 - @@@ Training the Model Nnet with 472 samples
2020-06-30 09:40:47,930 - TRAINING runs in 2 epochs
2020-06-30 09:40:47,930 -   TRAINING EPOCH 1 out of 2
2020-06-30 09:40:54,520 -   TRAINING EPOCH 2 out of 2
2020-06-30 09:41:00,488 - 
2020-06-30 09:41:00,489 - PITTING AGAINST PREVIOUS VERSION
2020-06-30 09:41:01,200 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -2,      [  5 /  -7 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:01,693 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns=  6 ,   score=  -2,      [  4 /  -6 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:03,848 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   5,      [ 15 / -10 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:05,946 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 19 ,   score=   5,      [ 14 /  -9 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:05,962 -   NEW/PREV WINS : 0 / 4 ; DRAWS : 0
2020-06-30 09:41:05,962 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.5208333333333333, Model Acceptance: 0 of 1
2020-06-30 09:41:05,998 - 
2020-06-30 09:41:05,998 - SAMPLE GEN ITERATION 2 of 2
2020-06-30 09:41:06,028 - @@@ Upgraded Model
2020-06-30 09:41:09,967 -   SAMPLE GEN EPISODE 1 of 3:  144 samples generated
2020-06-30 09:41:13,867 -   SAMPLE GEN EPISODE 2 of 3:  144 samples generated
2020-06-30 09:41:17,660 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-30 09:41:17,661 - Total Samples Collected: 432
2020-06-30 09:41:17,661 - @@@ Training the Model Nnet with 904 samples
2020-06-30 09:41:17,661 - TRAINING runs in 2 epochs
2020-06-30 09:41:17,661 -   TRAINING EPOCH 1 out of 2
2020-06-30 09:41:29,642 -   TRAINING EPOCH 2 out of 2
2020-06-30 09:41:42,402 - 
2020-06-30 09:41:42,402 - PITTING AGAINST PREVIOUS VERSION
2020-06-30 09:41:43,348 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:45,759 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -18,      [  3 / -21 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:47,701 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   9,      [ 17 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:49,840 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   9,      [ 17 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:41:49,857 -   NEW/PREV WINS : 0 / 4 ; DRAWS : 0
2020-06-30 09:41:49,857 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.5104166666666666, Model Acceptance: 0 of 2
2020-06-30 09:41:50,064 - Total Time Taken = 75.52117490768433 seconds
