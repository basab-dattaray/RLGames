2020-06-29 12:35:50,704 - @@@ DEMO NAME:: train_mini
2020-06-29 12:35:50,704 - @@@ PATH:: /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/train_mini.py
2020-06-29 12:35:50,705 - 
2020-06-29 12:35:50,705 - SESSION ID: session_1
2020-06-29 12:35:50,705 - model_acceptance_win_ratio=0.95
2020-06-29 12:35:50,705 - num_training_eval_games=4
2020-06-29 12:35:50,705 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-29 12:35:50,706 - num_episodes=3
2020-06-29 12:35:50,706 - num_iterations=2
2020-06-29 12:35:50,706 - epochs=2
2020-06-29 12:35:50,706 - num_of_mcts_simulations=12
2020-06-29 12:35:51,095 - @@@ Model loaded
2020-06-29 12:35:51,095 - 
2020-06-29 12:35:51,095 - SAMPLE GEN ITERATION 1 of 2
2020-06-29 12:35:51,134 - @@@ Upgraded Model
2020-06-29 12:35:55,571 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-29 12:36:00,157 -   SAMPLE GEN EPISODE 2 of 3:  160 samples generated
2020-06-29 12:36:04,090 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-29 12:36:04,090 - Total Samples Collected: 472
2020-06-29 12:36:04,091 - @@@ Training the Model Nnet with 472 samples
2020-06-29 12:36:04,091 - TRAINING runs in 2 epochs
2020-06-29 12:36:04,091 -   TRAINING EPOCH 1 out of 2
2020-06-29 12:36:10,809 -   TRAINING EPOCH 2 out of 2
2020-06-29 12:36:16,579 - 
2020-06-29 12:36:16,580 - PITTING AGAINST PREVIOUS VERSION
2020-06-29 12:36:18,884 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -12,      [  6 / -18 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:36:20,792 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -12,      [  6 / -18 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:36:22,970 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   3,      [ 14 / -11 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:36:25,209 - @@@ play game   4: result=  1,  first_player= -1, last_player=-1 turns= 21 ,   score=   1,      [ 13 / -12 /   0]  ==>  plusses trending: 25.0
2020-06-29 12:36:25,226 -   NEW/PREV WINS : 1 / 3 ; DRAWS : 0
2020-06-29 12:36:25,226 -   REJECTING NEW MODEL: win_ratio = 0.25 threshold: 0.8151041666666666, Model Acceptance: 0 of 1
2020-06-29 12:36:25,259 - 
2020-06-29 12:36:25,259 - SAMPLE GEN ITERATION 2 of 2
2020-06-29 12:36:25,287 - @@@ Upgraded Model
2020-06-29 12:36:29,212 -   SAMPLE GEN EPISODE 1 of 3:  144 samples generated
2020-06-29 12:36:33,144 -   SAMPLE GEN EPISODE 2 of 3:  144 samples generated
2020-06-29 12:36:37,071 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-29 12:36:37,071 - Total Samples Collected: 432
2020-06-29 12:36:37,072 - @@@ Training the Model Nnet with 904 samples
2020-06-29 12:36:37,072 - TRAINING runs in 2 epochs
2020-06-29 12:36:37,072 -   TRAINING EPOCH 1 out of 2
2020-06-29 12:36:50,548 -   TRAINING EPOCH 2 out of 2
2020-06-29 12:37:03,507 - 
2020-06-29 12:37:03,507 - PITTING AGAINST PREVIOUS VERSION
2020-06-29 12:37:05,599 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -12,      [  6 / -18 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:37:07,600 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -12,      [  6 / -18 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:37:09,028 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 15 ,   score=  13,      [ 16 /  -3 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:37:11,241 - @@@ play game   4: result= -1,  first_player= -1, last_player= 1 turns= 20 ,   score=   2,      [ 13 / -11 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:37:11,258 -   NEW/PREV WINS : 0 / 4 ; DRAWS : 0
2020-06-29 12:37:11,258 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.7625868055555555, Model Acceptance: 0 of 2
2020-06-29 12:37:11,461 - Total Time Taken = 80.75699400901794 seconds
