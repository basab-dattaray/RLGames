2020-06-30 09:51:26,084 - @@@ DEMO NAME:: train_mini
2020-06-30 09:51:26,085 - @@@ PATH:: /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/train_mini.py
2020-06-30 09:51:26,085 - 
2020-06-30 09:51:26,085 - SESSION ID: session_1
2020-06-30 09:51:26,085 - model_acceptance_win_ratio=0.6
2020-06-30 09:51:26,085 - win_ratio_reduction_rate=1
2020-06-30 09:51:26,086 - num_training_eval_games=4
2020-06-30 09:51:26,086 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-30 09:51:26,086 - num_episodes=3
2020-06-30 09:51:26,086 - num_iterations=2
2020-06-30 09:51:26,086 - epochs=2
2020-06-30 09:51:26,086 - num_of_mcts_simulations=12
2020-06-30 09:51:26,470 - @@@ Model loaded
2020-06-30 09:51:26,471 - 
2020-06-30 09:51:26,471 - SAMPLE GEN ITERATION 1 of 2
2020-06-30 09:51:26,525 - @@@ Upgraded Model
2020-06-30 09:51:31,269 -   SAMPLE GEN EPISODE 1 of 3:  160 samples generated
2020-06-30 09:51:35,900 -   SAMPLE GEN EPISODE 2 of 3:  160 samples generated
2020-06-30 09:51:40,011 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-30 09:51:40,011 - Total Samples Collected: 464
2020-06-30 09:51:40,011 - @@@ Training the Model Nnet with 464 samples
2020-06-30 09:51:40,011 - TRAINING runs in 2 epochs
2020-06-30 09:51:40,011 -   TRAINING EPOCH 1 out of 2
2020-06-30 09:51:47,187 -   TRAINING EPOCH 2 out of 2
2020-06-30 09:51:53,025 - 
2020-06-30 09:51:53,025 - PITTING AGAINST PREVIOUS VERSION
2020-06-30 09:51:53,819 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:51:54,538 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:51:56,699 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=  13,      [ 19 /  -6 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:51:58,958 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:51:58,975 -   NEW/PREV WINS : 0 / 4 ; DRAWS : 0
2020-06-30 09:51:58,976 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.5104166666666666, Model Acceptance: 0 of 1
2020-06-30 09:51:59,010 - 
2020-06-30 09:51:59,010 - SAMPLE GEN ITERATION 2 of 2
2020-06-30 09:51:59,037 - @@@ Upgraded Model
2020-06-30 09:52:03,096 -   SAMPLE GEN EPISODE 1 of 3:  144 samples generated
2020-06-30 09:52:07,100 -   SAMPLE GEN EPISODE 2 of 3:  144 samples generated
2020-06-30 09:52:10,909 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-30 09:52:10,909 - Total Samples Collected: 432
2020-06-30 09:52:10,910 - @@@ Training the Model Nnet with 896 samples
2020-06-30 09:52:10,910 - TRAINING runs in 2 epochs
2020-06-30 09:52:10,910 -   TRAINING EPOCH 1 out of 2
2020-06-30 09:52:23,046 -   TRAINING EPOCH 2 out of 2
2020-06-30 09:52:34,873 - 
2020-06-30 09:52:34,873 - PITTING AGAINST PREVIOUS VERSION
2020-06-30 09:52:37,047 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score= -16,      [  4 / -20 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:52:37,782 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -2,      [  5 /  -7 /   0]  ==>  plusses trending: 0.0
2020-06-30 09:52:40,117 - @@@ play game   3: result=  0,  first_player= -1, last_player= 1 turns= 18 ,   score=   0,      [ 11 / -11 /   0]  ==>  plusses trending: 16.666666666666664
2020-06-30 09:52:41,853 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 13 ,   score=   5,      [ 11 /  -6 /   0]  ==>  plusses trending: 12.5
2020-06-30 09:52:41,871 -   NEW/PREV WINS : 0 / 3 ; DRAWS : 1
2020-06-30 09:52:41,871 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.5052083333333333, Model Acceptance: 0 of 2
2020-06-30 09:52:42,079 - Total Time Taken = 75.99437999725342 seconds
