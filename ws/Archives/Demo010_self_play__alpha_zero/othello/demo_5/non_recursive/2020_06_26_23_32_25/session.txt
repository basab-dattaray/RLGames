2020-06-26 23:31:18,369 - 
2020-06-26 23:31:18,369 - SESSION ID: session_1
2020-06-26 23:31:18,369 - model_acceptance_win_ratio=0.5
2020-06-26 23:31:18,369 - num_training_eval_games=4
2020-06-26 23:31:18,369 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS', 'POLICY_TRAINING_EVAL': 'DIRECT_MODEL'}
2020-06-26 23:31:18,369 - num_episodes=3
2020-06-26 23:31:18,369 - num_iterations=2
2020-06-26 23:31:18,369 - epochs=2
2020-06-26 23:31:18,369 - num_of_mcts_simulations=12
2020-06-26 23:31:18,714 - fn_load_model; No File /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/workspace/model.tar available for Loading
2020-06-26 23:31:18,714 - 
2020-06-26 23:31:18,714 - SAMPLE GEN ITERATION 1 of 2
2020-06-26 23:31:23,431 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-26 23:31:28,098 -   SAMPLE GEN EPISODE 2 of 3:  168 samples generated
2020-06-26 23:31:32,805 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-26 23:31:32,805 - Total Samples Collected: 504
2020-06-26 23:31:32,847 - @@@ Upgraded Model
2020-06-26 23:31:32,847 - @@@ Training the Model Nnet with 504 samples
2020-06-26 23:31:32,848 - TRAINING runs in 2 epochs
2020-06-26 23:31:32,848 -   TRAINING EPOCH 1 out of 2
2020-06-26 23:31:39,134 -   TRAINING EPOCH 2 out of 2
2020-06-26 23:31:45,016 - 
2020-06-26 23:31:45,016 - PITTING AGAINST PREVIOUS VERSION
2020-06-26 23:31:45,198 - @@@ play game   1: result=  1,  first_player=  1, last_player= 1 turns= 17 ,   score=  13,      [ 17 /  -4 /   0]  ==>  plusses trending: 100.0
2020-06-26 23:31:45,446 - @@@ play game   2: result=  1,  first_player=  1, last_player= 1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 100.0
2020-06-26 23:31:45,605 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns= 14 ,   score= -12,      [  3 / -15 /   0]  ==>  plusses trending: 100.0
2020-06-26 23:31:45,847 - @@@ play game   4: result=  0,  first_player= -1, last_player= 1 turns= 20 ,   score=   0,      [ 12 / -12 /   0]  ==>  plusses trending: 87.5
2020-06-26 23:31:45,863 -   NEW/PREV WINS : 3 / 0 ; DRAWS : 1
2020-06-26 23:31:45,863 -   ACCEPTING NEW MODEL: win_ratio = 1.0 threshold: 0.5 Model Acceptance: 1 of 1
2020-06-26 23:31:45,901 - @@@ Saved samples: 1 batches comprising 504 samples
2020-06-26 23:31:45,921 - 
2020-06-26 23:31:45,921 - SAMPLE GEN ITERATION 2 of 2
2020-06-26 23:31:50,465 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-26 23:31:54,975 -   SAMPLE GEN EPISODE 2 of 3:  168 samples generated
2020-06-26 23:31:59,501 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-26 23:31:59,501 - Total Samples Collected: 504
2020-06-26 23:31:59,535 - @@@ Upgraded Model
2020-06-26 23:31:59,535 - @@@ Training the Model Nnet with 1008 samples
2020-06-26 23:31:59,535 - TRAINING runs in 2 epochs
2020-06-26 23:31:59,536 -   TRAINING EPOCH 1 out of 2
2020-06-26 23:32:11,627 -   TRAINING EPOCH 2 out of 2
2020-06-26 23:32:24,030 - 
2020-06-26 23:32:24,030 - PITTING AGAINST PREVIOUS VERSION
2020-06-26 23:32:24,203 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 16 ,   score=  -8,      [  6 / -14 /   0]  ==>  plusses trending: 0.0
2020-06-26 23:32:24,442 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score=  -6,      [  9 / -15 /   0]  ==>  plusses trending: 0.0
2020-06-26 23:32:24,630 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns= 16 ,   score=  -8,      [  6 / -14 /   0]  ==>  plusses trending: 33.33333333333333
2020-06-26 23:32:24,869 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   9,      [ 17 /  -8 /   0]  ==>  plusses trending: 25.0
2020-06-26 23:32:24,886 -   NEW/PREV WINS : 1 / 3 ; DRAWS : 0
2020-06-26 23:32:24,886 -   REJECTING NEW MODEL: win_ratio = 0.25 threshold: 0.5, Model Acceptance: 1 of 2
2020-06-26 23:32:25,046 - Total Time Taken = 66.68176007270813 seconds
