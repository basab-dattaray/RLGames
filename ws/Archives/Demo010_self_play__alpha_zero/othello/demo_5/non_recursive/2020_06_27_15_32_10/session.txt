2020-06-27 15:30:49,308 - 
2020-06-27 15:30:49,308 - SESSION ID: session_1
2020-06-27 15:30:49,309 - model_acceptance_win_ratio=0.6
2020-06-27 15:30:49,309 - num_training_eval_games=4
2020-06-27 15:30:49,309 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS', 'POLICY_TRAINING_EVAL': 'DIRECT_MODEL'}
2020-06-27 15:30:49,309 - num_episodes=3
2020-06-27 15:30:49,309 - num_iterations=2
2020-06-27 15:30:49,309 - epochs=2
2020-06-27 15:30:49,310 - num_of_mcts_simulations=12
2020-06-27 15:31:01,624 - fn_load_model; No File /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/workspace/model.tar available for Loading
2020-06-27 15:31:01,624 - 
2020-06-27 15:31:01,624 - SAMPLE GEN ITERATION 1 of 2
2020-06-27 15:31:06,939 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-27 15:31:09,595 -   SAMPLE GEN EPISODE 2 of 3:  !!! No Samples were generated
2020-06-27 15:31:14,859 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-27 15:31:14,859 - Total Samples Collected: 336
2020-06-27 15:31:14,908 - @@@ Upgraded Model
2020-06-27 15:31:14,908 - @@@ Training the Model Nnet with 336 samples
2020-06-27 15:31:14,909 - TRAINING runs in 2 epochs
2020-06-27 15:31:14,909 -   TRAINING EPOCH 1 out of 2
2020-06-27 15:31:19,240 -   TRAINING EPOCH 2 out of 2
2020-06-27 15:31:23,603 - 
2020-06-27 15:31:23,603 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 15:31:23,858 - @@@ play game   1: result= -1,  first_player=  1, last_player= 1 turns= 19 ,   score=  -7,      [  8 / -15 /   0]  ==>  plusses trending: 0.0
2020-06-27 15:31:24,038 - @@@ play game   2: result= -1,  first_player=  1, last_player= 1 turns= 13 ,   score=   1,      [  9 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-27 15:31:24,336 - @@@ play game   3: result=  1,  first_player= -1, last_player=-1 turns= 21 ,   score=  -9,      [  8 / -17 /   0]  ==>  plusses trending: 33.33333333333333
2020-06-27 15:31:24,625 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=   3,      [ 14 / -11 /   0]  ==>  plusses trending: 25.0
2020-06-27 15:31:24,646 -   NEW/PREV WINS : 1 / 3 ; DRAWS : 0
2020-06-27 15:31:34,312 -   ACCEPTING NEW MODEL: win_ratio = 0.25 threshold: 0.6 Model Acceptance: 1 of 1
2020-06-27 15:31:34,347 - @@@ Saved samples: 1 batches comprising 336 samples
2020-06-27 15:31:34,367 - 
2020-06-27 15:31:34,368 - SAMPLE GEN ITERATION 2 of 2
2020-06-27 15:31:38,330 -   SAMPLE GEN EPISODE 1 of 3:  !!! No Samples were generated
2020-06-27 15:31:42,424 -   SAMPLE GEN EPISODE 2 of 3:  !!! No Samples were generated
2020-06-27 15:31:47,424 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-27 15:31:47,424 - Total Samples Collected: 168
2020-06-27 15:31:47,465 - @@@ Upgraded Model
2020-06-27 15:31:47,465 - @@@ Training the Model Nnet with 504 samples
2020-06-27 15:31:47,466 - TRAINING runs in 2 epochs
2020-06-27 15:31:47,466 -   TRAINING EPOCH 1 out of 2
2020-06-27 15:31:53,167 -   TRAINING EPOCH 2 out of 2
2020-06-27 15:31:58,993 - 
2020-06-27 15:31:58,994 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 15:31:59,260 - @@@ play game   1: result=  1,  first_player=  1, last_player= 1 turns= 21 ,   score=  21,      [ 23 /  -2 /   0]  ==>  plusses trending: 100.0
2020-06-27 15:31:59,553 - @@@ play game   2: result= -1,  first_player=  1, last_player= 1 turns= 21 ,   score=  -3,      [ 11 / -14 /   0]  ==>  plusses trending: 50.0
2020-06-27 15:31:59,817 - @@@ play game   3: result= -1,  first_player= -1, last_player= 1 turns= 18 ,   score=   4,      [ 13 /  -9 /   0]  ==>  plusses trending: 33.33333333333333
2020-06-27 15:32:00,111 - @@@ play game   4: result=  1,  first_player= -1, last_player= 1 turns= 20 ,   score=  -4,      [ 10 / -14 /   0]  ==>  plusses trending: 50.0
2020-06-27 15:32:00,131 -   NEW/PREV WINS : 2 / 2 ; DRAWS : 0
2020-06-27 15:32:10,497 -   ACCEPTING NEW MODEL: win_ratio = 0.5 threshold: 0.6 Model Acceptance: 2 of 2
2020-06-27 15:32:10,555 - @@@ Saved samples: 2 batches comprising 504 samples
2020-06-27 15:32:10,864 - Total Time Taken = 81.56054401397705 seconds
