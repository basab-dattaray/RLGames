2020-06-29 12:37:41,064 - @@@ DEMO NAME:: train_mini
2020-06-29 12:37:41,064 - @@@ PATH:: /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/non_recursive/train_mini.py
2020-06-29 12:37:41,066 - 
2020-06-29 12:37:41,066 - SESSION ID: session_1
2020-06-29 12:37:41,066 - model_acceptance_win_ratio=0.95
2020-06-29 12:37:41,066 - num_training_eval_games=4
2020-06-29 12:37:41,066 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-29 12:37:41,066 - num_episodes=3
2020-06-29 12:37:41,066 - num_iterations=2
2020-06-29 12:37:41,066 - epochs=2
2020-06-29 12:37:41,066 - num_of_mcts_simulations=12
2020-06-29 12:37:41,618 - @@@ Model loaded
2020-06-29 12:37:41,618 - 
2020-06-29 12:37:41,619 - SAMPLE GEN ITERATION 1 of 2
2020-06-29 12:37:41,653 - @@@ Upgraded Model
2020-06-29 12:37:46,203 -   SAMPLE GEN EPISODE 1 of 3:  160 samples generated
2020-06-29 12:37:50,806 -   SAMPLE GEN EPISODE 2 of 3:  160 samples generated
2020-06-29 12:37:54,766 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-29 12:37:54,766 - Total Samples Collected: 464
2020-06-29 12:37:54,766 - @@@ Training the Model Nnet with 464 samples
2020-06-29 12:37:54,767 - TRAINING runs in 2 epochs
2020-06-29 12:37:54,767 -   TRAINING EPOCH 1 out of 2
2020-06-29 12:38:01,473 -   TRAINING EPOCH 2 out of 2
2020-06-29 12:38:07,364 - 
2020-06-29 12:38:07,365 - PITTING AGAINST PREVIOUS VERSION
2020-06-29 12:38:09,432 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score=  -8,      [  8 / -16 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:11,213 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score=  -8,      [  8 / -16 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:13,340 - @@@ play game   3: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:15,349 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:15,368 -   NEW/PREV WINS : 0 / 4 ; DRAWS : 0
2020-06-29 12:38:15,368 -   REJECTING NEW MODEL: win_ratio = 0.0 threshold: 0.9499999999999998, Model Acceptance: 0 of 1
2020-06-29 12:38:15,402 - 
2020-06-29 12:38:15,402 - SAMPLE GEN ITERATION 2 of 2
2020-06-29 12:38:15,431 - @@@ Upgraded Model
2020-06-29 12:38:19,537 -   SAMPLE GEN EPISODE 1 of 3:  144 samples generated
2020-06-29 12:38:23,540 -   SAMPLE GEN EPISODE 2 of 3:  144 samples generated
2020-06-29 12:38:27,371 -   SAMPLE GEN EPISODE 3 of 3:  144 samples generated
2020-06-29 12:38:27,371 - Total Samples Collected: 432
2020-06-29 12:38:27,371 - @@@ Training the Model Nnet with 896 samples
2020-06-29 12:38:27,372 - TRAINING runs in 2 epochs
2020-06-29 12:38:27,372 -   TRAINING EPOCH 1 out of 2
2020-06-29 12:38:38,963 -   TRAINING EPOCH 2 out of 2
2020-06-29 12:38:52,746 - 
2020-06-29 12:38:52,747 - PITTING AGAINST PREVIOUS VERSION
2020-06-29 12:38:54,867 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score=  -8,      [  8 / -16 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:57,187 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns= 20 ,   score=  -6,      [  9 / -15 /   0]  ==>  plusses trending: 0.0
2020-06-29 12:38:59,463 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns= 20 ,   score=  -2,      [ 11 / -13 /   0]  ==>  plusses trending: 33.33333333333333
2020-06-29 12:39:01,738 - @@@ play game   4: result= -1,  first_player= -1, last_player=-1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 25.0
2020-06-29 12:39:01,757 -   NEW/PREV WINS : 1 / 3 ; DRAWS : 0
2020-06-29 12:39:01,757 -   REJECTING NEW MODEL: win_ratio = 0.25 threshold: 0.8749999999999999, Model Acceptance: 0 of 2
2020-06-29 12:39:01,956 - Total Time Taken = 80.89274907112122 seconds
