2020-06-27 16:15:42,998 - 
2020-06-27 16:15:42,998 - SESSION ID: session_1
2020-06-27 16:15:42,998 - model_acceptance_win_ratio=0.95
2020-06-27 16:15:42,998 - num_training_eval_games=4
2020-06-27 16:15:42,998 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-27 16:15:42,998 - num_episodes=3
2020-06-27 16:15:42,998 - num_iterations=2
2020-06-27 16:15:42,998 - epochs=2
2020-06-27 16:15:42,998 - num_of_mcts_simulations=12
2020-06-27 16:15:43,351 - fn_load_model; No File /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/recursive/workspace/model.tar available for Loading
2020-06-27 16:15:43,351 - 
2020-06-27 16:15:43,351 - SAMPLE GEN ITERATION 1 of 2
2020-06-27 16:15:48,046 -   SAMPLE GEN EPISODE 1 of 3:  168 samples generated
2020-06-27 16:15:52,504 -   SAMPLE GEN EPISODE 2 of 3:  168 samples generated
2020-06-27 16:15:53,846 -   SAMPLE GEN EPISODE 3 of 3:  !!! No Samples were generated
2020-06-27 16:15:53,846 - Total Samples Collected: 336
2020-06-27 16:15:53,887 - @@@ Upgraded Model
2020-06-27 16:15:53,888 - @@@ Training the Model Nnet with 336 samples
2020-06-27 16:15:53,888 - TRAINING runs in 2 epochs
2020-06-27 16:15:53,888 -   TRAINING EPOCH 1 out of 2
2020-06-27 16:15:58,582 -   TRAINING EPOCH 2 out of 2
2020-06-27 16:16:02,922 - 
2020-06-27 16:16:02,922 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 16:16:05,065 - @@@ play game   1: result=  1,  first_player=  1, last_player= 1 turns= 21 ,   score=   7,      [ 16 /  -9 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:07,342 - @@@ play game   2: result=  1,  first_player=  1, last_player= 1 turns= 21 ,   score=  11,      [ 18 /  -7 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:09,639 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns= 18 ,   score=  -4,      [  9 / -13 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:10,135 - @@@ play game   4: result=  1,  first_player= -1, last_player= 1 turns=  6 ,   score=  -2,      [  4 /  -6 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:10,150 -   NEW/PREV WINS : 4 / 0 ; DRAWS : 0
2020-06-27 16:16:10,150 -   ACCEPTING NEW MODEL: win_ratio = 1.0 threshold: 0.95 Model Acceptance: 1 of 1
2020-06-27 16:16:10,179 - @@@ Saved samples: 1 batches comprising 336 samples
2020-06-27 16:16:10,195 - 
2020-06-27 16:16:10,195 - SAMPLE GEN ITERATION 2 of 2
2020-06-27 16:16:14,673 -   SAMPLE GEN EPISODE 1 of 3:  !!! No Samples were generated
2020-06-27 16:16:18,866 -   SAMPLE GEN EPISODE 2 of 3:  168 samples generated
2020-06-27 16:16:23,252 -   SAMPLE GEN EPISODE 3 of 3:  !!! No Samples were generated
2020-06-27 16:16:23,252 - Total Samples Collected: 168
2020-06-27 16:16:23,282 - @@@ Upgraded Model
2020-06-27 16:16:23,282 - @@@ Training the Model Nnet with 504 samples
2020-06-27 16:16:23,283 - TRAINING runs in 2 epochs
2020-06-27 16:16:23,283 -   TRAINING EPOCH 1 out of 2
2020-06-27 16:16:29,151 -   TRAINING EPOCH 2 out of 2
2020-06-27 16:16:35,009 - 
2020-06-27 16:16:35,009 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 16:16:37,148 - @@@ play game   1: result=  1,  first_player=  1, last_player= 1 turns= 19 ,   score=   7,      [ 15 /  -8 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:39,392 - @@@ play game   2: result=  1,  first_player=  1, last_player=-1 turns= 20 ,   score=   8,      [ 16 /  -8 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:40,013 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:41,706 - @@@ play game   4: result=  1,  first_player= -1, last_player= 1 turns= 16 ,   score= -10,      [  5 / -15 /   0]  ==>  plusses trending: 100.0
2020-06-27 16:16:41,723 -   NEW/PREV WINS : 4 / 0 ; DRAWS : 0
2020-06-27 16:16:41,723 -   ACCEPTING NEW MODEL: win_ratio = 1.0 threshold: 0.9125 Model Acceptance: 2 of 2
2020-06-27 16:16:41,766 - @@@ Saved samples: 2 batches comprising 504 samples
2020-06-27 16:16:41,929 - Total Time Taken = 58.935890913009644 seconds
