2020-06-27 21:49:38,484 - 
2020-06-27 21:49:38,485 - SESSION ID: session_1
2020-06-27 21:49:38,485 - model_acceptance_win_ratio=0.95
2020-06-27 21:49:38,485 - num_training_eval_games=4
2020-06-27 21:49:38,485 - POLICY_RULES={'POLICY_TRAINING_EXECUTION': 'MCTS_RECURSIVE', 'POLICY_TRAINING_EVAL': 'MCTS_RECURSIVE'}
2020-06-27 21:49:38,485 - num_episodes=3
2020-06-27 21:49:38,485 - num_iterations=2
2020-06-27 21:49:38,485 - epochs=2
2020-06-27 21:49:38,485 - num_of_mcts_simulations=12
2020-06-27 21:49:38,841 - fn_load_model; No File /Users/bd/Documents/WorkSpace/DeepLearning/dev/alpha-zero-general/ws/Demos/Demo010_self_play__alpha_zero/othello/demo_5/recursive/workspace/model.tar available for Loading
2020-06-27 21:49:38,841 - 
2020-06-27 21:49:38,841 - SAMPLE GEN ITERATION 1 of 2
2020-06-27 21:49:40,743 -   SAMPLE GEN EPISODE 1 of 3:  !!! No Samples were generated
2020-06-27 21:49:42,998 -   SAMPLE GEN EPISODE 2 of 3:  !!! No Samples were generated
2020-06-27 21:49:47,453 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-27 21:49:47,453 - Total Samples Collected: 168
2020-06-27 21:49:47,498 - @@@ Upgraded Model
2020-06-27 21:49:47,498 - @@@ Training the Model Nnet with 168 samples
2020-06-27 21:49:47,498 - TRAINING runs in 2 epochs
2020-06-27 21:49:47,498 -   TRAINING EPOCH 1 out of 2
2020-06-27 21:49:49,216 -   TRAINING EPOCH 2 out of 2
2020-06-27 21:49:51,458 - 
2020-06-27 21:49:51,458 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 21:49:52,196 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-27 21:49:53,097 - @@@ play game   2: result=  0,  first_player=  1, last_player=-1 turns=  8 ,   score=   0,      [  6 /  -6 /   0]  ==>  plusses trending: 25.0
2020-06-27 21:49:54,722 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns= 14 ,   score= -12,      [  3 / -15 /   0]  ==>  plusses trending: 50.0
2020-06-27 21:49:55,255 - @@@ play game   4: result=  1,  first_player= -1, last_player= 1 turns=  6 ,   score=  -2,      [  4 /  -6 /   0]  ==>  plusses trending: 62.5
2020-06-27 21:49:55,271 -   NEW/PREV WINS : 2 / 1 ; DRAWS : 1
2020-06-27 21:49:55,271 -   REJECTING NEW MODEL: win_ratio = 0.6666666666666666 threshold: 0.95, Model Acceptance: 0 of 1
2020-06-27 21:49:55,306 - 
2020-06-27 21:49:55,306 - SAMPLE GEN ITERATION 2 of 2
2020-06-27 21:49:57,374 -   SAMPLE GEN EPISODE 1 of 3:  !!! No Samples were generated
2020-06-27 21:50:01,750 -   SAMPLE GEN EPISODE 2 of 3:  !!! No Samples were generated
2020-06-27 21:50:06,150 -   SAMPLE GEN EPISODE 3 of 3:  168 samples generated
2020-06-27 21:50:06,150 - Total Samples Collected: 168
2020-06-27 21:50:06,186 - @@@ Upgraded Model
2020-06-27 21:50:06,186 - @@@ Training the Model Nnet with 336 samples
2020-06-27 21:50:06,186 - TRAINING runs in 2 epochs
2020-06-27 21:50:06,186 -   TRAINING EPOCH 1 out of 2
2020-06-27 21:50:10,627 -   TRAINING EPOCH 2 out of 2
2020-06-27 21:50:14,935 - 
2020-06-27 21:50:14,935 - PITTING AGAINST PREVIOUS VERSION
2020-06-27 21:50:17,700 - @@@ play game   1: result= -1,  first_player=  1, last_player=-1 turns= 18 ,   score=  -8,      [  7 / -15 /   0]  ==>  plusses trending: 0.0
2020-06-27 21:50:18,550 - @@@ play game   2: result= -1,  first_player=  1, last_player=-1 turns=  8 ,   score=  -4,      [  4 /  -8 /   0]  ==>  plusses trending: 0.0
2020-06-27 21:50:19,036 - @@@ play game   3: result=  1,  first_player= -1, last_player= 1 turns=  6 ,   score=  -2,      [  4 /  -6 /   0]  ==>  plusses trending: 33.33333333333333
2020-06-27 21:50:19,556 - @@@ play game   4: result=  1,  first_player= -1, last_player= 1 turns=  6 ,   score=  -2,      [  4 /  -6 /   0]  ==>  plusses trending: 50.0
2020-06-27 21:50:19,574 -   NEW/PREV WINS : 2 / 2 ; DRAWS : 0
2020-06-27 21:50:19,574 -   REJECTING NEW MODEL: win_ratio = 0.5 threshold: 0.9125, Model Acceptance: 0 of 2
2020-06-27 21:50:19,739 - *** WARNING: Model was not created
2020-06-27 21:50:19,740 - Total Time Taken = 41.256869077682495 seconds
